Considerato che siamo interessati a computazioni di grana fine si sono considerare matrici con un numero di righe relativamente basso: $\mathrm{M} \in \{\,56, 168, 280\,\}$. Con il massimo grado di parallelismo, infatti, abbiamo partizioni di dimensione $g \in \{\,1, 3, 5\,\}$ righe, rispettivamente; conseguentemente, il calcolo svolto nei worker in tale situazione prevede $g\cdot\mathrm{M}$ moltiplicazioni e altrettante somme. Per ogni dimensione di matrice si sono eseguite istanze del programma di benchmark con grado di parallelismo della Map variabile. In ogni caso si \`e scelto $n$ divisore di $\mathrm{M}$.

Dato che non \`e imposto il tempo di interarrivo, si vorrebbe stimare il tempo di servizio della Map con il massimo numero di nodi disponibili, in modo tale da conoscere quale \`e la banda massima dello stream in cui il nostro sottosistema parallelo effettua il calcolo, producendo i risultati con la stessa velocit\`a. 
L'equazione da usare \`e quella mostrata precedentemente in formula~\ref{eq:impl_TsubsysId}. Se invece fosse noto il tempo di interarrivo dello stream, si userebbe l'equazione di formula~\ref{eq:impl_nopt} per ricavare il minimo numero di nodi worker necessari per eliminare il collo di bottiglia. Una previsione effettiva del comportamento del sistema stima i valori di \Tcalc\ e \deltacom per mezzo di simulazioni o applicando con modelli di costo formali che caratterizzano vari aspetti dell'architettura.

L'applicazione di modelli di costi all'architettura \tile\ non \`e lo scopo del tirocinio, si \`e quindi usato un approccio molto pi\`u semplice: \`e stimato in modo rudimentale il tempo di servizio ideale sostituendo nella formula~\ref{eq:impl_TsubsysId}, al  \Tcalc\ la misura del tempo di completamento effettuata sul programma sequenziale eseguito nella CPU di un singolo PE, e al \deltacom\ la misura della latenza di comunicazione descritta nell'esperimento precedente (sezione~\ref{sct:meter_risultati}).
Quello che otteniamo \`e una valutazione molto elementare del tempo di servizio che difficilmente sar\`a riscontrata nell'esecuzione del programma, perch\'e, ad esempio, non si \`e tenuto conto dell'aumento della latenza di accesso alla memoria con l'incremento del grado di parallelismo.
Nelle tabelle~\ref{tab:Tcalc},~\ref{tab:deltacom} sono riassunte le misure dei due parametri; in tabella~\ref{tab:TsubsysId} sono presentati i valori calcolati del tempo di servizio con il massimo grado di parallelismo ($N=59$). Il tempo di servizio effettivo del sistema viene mostrato nella sezione seguente.

\input{Benchmark_Tables_1}


\FloatBarrier

\subsubsection*{Misura dei tempi di completamento e di servizio al variare del tempo di ingresso}
Si sono sperimentate pi\`u esecuzioni dell'applicazione con diversi valori del tempo di interarrivo dello stream: 
\begin{enumerate}  
\item viene considerata una banda di arrivi per la quale non si riesce ad eliminare il collo di bottiglia; in particolare questo esperimento ci mostra qual'\`e il tempo di servizio effettivo che assume il sottosistema;
\item Una volta noto il tempo di servizio effettivo si considerano velocit\`a degli arrivi superiori a questo valore, per i quali deve essere eliminato il collo di bottiglia. Scopo di questi esperimenti \`e verificare che il collo di bottiglia sia effettivamente eliminato, e con che grado di parallelismo $n$ si riesce ad eliminare, in particolare se il valore di questo $n$ \`e vicino a quello stimato con la formula~\ref{eq:impl_nopt}.
%% scopo di questi esperimenti \`e verificare tale comportamento del sistema ed accertarsi che la scalabilit\`a del tempo di servizio sia simile al grado di parallelismo ottimo calcolato con la formula~\ref{eq:impl_nopt}.
\end{enumerate}     
I risultati degli esperimenti fatti sono mostrati in figura~\ref{fig:serviceTime} per quanto riguarda il tempo di servizio della Map, e in figura~\ref{fig:completeTime} per il tempo di completamento dello stream. La scalabilit\`a \`e calcolata con la formula~\ref{eq:s} sostituendo al tempo di calcolo, quello misurato sul programma sequenziale e presentato in tabella~\ref{tab:Tcalc}. I grafici di scalabilit\`a sono quindi mostrati in figura~\ref{fig:completeTimeScalability}. Si ricorda che il tempo di servizio effettivo della Map \`e il massimo tra il tempo di interarrivo e il tempo di servizio ideale, costituito, quest'ultimo, dal tempo di calcolo sulla partizione della matrice, pi\`u \deltacom\ il tempo speso nelle comunicazioni. Per un generico tempo di interarrivo abbiamo due possibili soluzioni:
\begin{description}   
\item [la Map \`e collo di bottiglia:] \`e interessante verificare quale sia il tempo di interarrivo effettivo della Map, e di conseguenza la massima scalabilit\`a effettiva della Map. In precedenza si \`e infatti osservato che le formule usate per stimare il tempo di servizio della Map non applicano alcun modello dei costi relativo ad aspetti dell'architettura, ma si limitano ad usare le misure su computazioni particolari. In seguito ai conflitti sulle reti di interconnessione e sui sottosistemi della gerarchia di memoria si prevede un aumento del tempo di calcolo nei worker, rispetto a $\frac{\inTcalc}{n}$, e un aumento della latenza di comunicazione, rispetto a quella misurata. Applicando la formula del $n_{\mathrm{opt}}$ ai valori effettivi del tempo di calcolo e della latenza di comunicazione si ottiene un valore maggiore rispetto a quello stimato inizialmente. 
%Allo stesso modo si trova un valore di tempo di servizio ideale maggiore. 
La tabella~\ref{tab:scalability_serviceTime_bottleneck} mostra i tempi di servizio effettivi, per le varie dimensioni delle matrici. Questi sono molto superiori ai tempi di servizio ideali relativi al massimo $n$ esplicitabile (59), mostrati in tabella~\ref{tab:TsubsysId}.

%% in questo caso si valuta la scalabilit\`a come 
%%   \[ \inscal = \frac{\inTcalc}{\frac{\inTcalc}{n} + \indeltacom} \]
%%   La tabella~\ref{tab:scalability_serviceTime_bottleneck} propone il miglior tempo di servizio per le esecuzioni del programma in cui la Map \`e collo di bottiglia. Tale valore \`e il minimo tempo di servizio raggiungibile: una qualsiasi altra esecuzione con tempo di interarrivo inferiore fornisce gli stessi risultati di tempo di servizio del sistema.

\item [la Map non \`e collo di bottiglia:] esiste un certo grado di parallelismo, esplicitabile dalla macchina, per cui il tempo di servizio ideale della Map \`e inferiore al tempo di interarrivo. Indipendentemente da un ulteriore aumento di $n$, il tempo di servizio effettivo del sistema rimane costante al tempo di interarrivo e la scalabilit\`a rimane sempre uguale al grado di parallelismo ottimo. \`E possibile che con l'aumentare del grado di parallelismo si creino delle degradazioni per cui il tempo di interarrivo e la scalabilit\`a diminuiscono leggermente rispetto a quelli dell'$n$ ottimo. 

Le misure effettuate mostrano che il tempo di servizio effettivo del sistema raggiunge il tempo di interarrivo con un valore di $n$ ``vicino a quello ottimo''. Stesso ragionamento si applica alla scalabilit\`a, la quale raggiunge il valore ottimo di $n$ con un grado di parallelismo vicino a questo valore. I valori misurati per alcuni tempi di interarrivo sono mostrati nella tabella~\ref{tab:scalability_serviceTime_noBottleneck}. Il comportamento del sistema \`e quindi quello atteso. Si osserva inoltre che la stima del grado di parallelismo ottimo \`e tanto migliore quanto la dimensione della matrice \`e pi\`u grande.
%% Tale situazione risulta verificata nelle misure degli esperimenti, con tempi di interarrivo elevati, in tabella~\ref{tab:scalability_serviceTime_noBottleneck} sono mostrati i migliori tempi di servizio, e corrispondente scalablit\`a e grado di parallelismo usato, quando la Map non \`e collo di bottiglia.
\end{description}      

\input{Benchmark_Tables_2}

\FloatBarrier

\input{Benchmark_ServiceTime}
\input{Benchmark_CompleteTime}
\input{Benchmark_CompleteTimeScalability}

\FloatBarrier

\subsubsection*{Analisi delle possibili degradazioni}
Si \`e indagato su quali siano le cause della cattiva scalabilit\`a che caratterizzano le esecuzioni, in particolar modo quella con dimensione minore dei dati. Esiste una parte, o pi\`u parti, del sistema che non si comporta come descritto dalla formula applicata per calcolare la scalabilit\`a. 
  Il sistema pu\`o essere visto come costituito da tre fasi collegate in pipeline: multicast, calcolo, gather. Il programma \`e stato rieseguito misurando il tempo di servizio di ciascuna fase, al fine di verificare il comportamento effettivo del sistema. Da tali misurazioni non risulta problematica la fase di gathering, mentre sono le altre due fasi che aumentano il proprio tempo di servizio con il crescere di $n$. 
\begin{description}
\item [fase di calcolo] le misure del tempo di calcolo sono proposte in maniera leggermente elaborata nelle figura~\ref{fig:rowTime_int}: viene esposto il rapporto tra i tempi di calcolo di un singolo prodotto scalare nel programma sequenziale e nel calcolo di un worker del sistema parallelo di grado $n$. Tale rapporto dovrebbe essere costante, indipendentemente dal grado di parallelismo; si osserva tuttavia un aumento di tale rapporto al crescere di $n$. Questa degradazione \`e tanto maggiore quanto pi\`u piccole sono le dimensioni dei dati. \`E ragionevole ipotizzare la causa di questo comportamento come l'aumento del tempo di risposta alla memoria indotto dall'incremento del numero di richieste alla memoria prodotto da valori crescenti di $n$. Come spiegato precedentemente, l'aumento del numero di clienti in una computazione \emph{client-server domanda-e-risposta} produce un aumento del tempo di risposta medio del servente. Inoltre il fatto che la degradazione sia maggiore con dimensione pi\`u piccola della matrice porta a convincersi di tale ragionamento, in quanto la diminuzione della dimensione dei dati porta ad un calo della grana di computazione dei worker, e quindi ad un aumento della frequenza di accessi alla memoria (controllore o L2 cache home) dovuti al verificarsi di un fault nella cache locale. Per convincersi di tale ragionamento, e grazie ad una particolare caratteristica architetturale, \`e stato effettuato un ulteriore esperimento, mostrato in figura~\ref{fig:rowTime_float}: la stessa misurazione \`e presa per dati in virgola mobile.  I core di \tile\ non dispongono di unit\`a di elaborazione firmware per i calcoli in virgola mobile, pertanto tali conti vengono interpretati a livello assembler. Ne segue che un calcolo aritmetico in virgola mobile viene interpretato come molte istruzioni assembler. Rispetto allo stesso calcolo con tipi interi, si ha una frequenza di accesso alla memoria inferiore, con conseguente riduzione del tempo di risposta. Il comportamento mostrato dall'esperimento con dati float ha infatti il tempo di calcolo del singolo prodotto scalare costante (o quasi) per tutte le dimensioni della matrice.
\item [fase di multicast] dato che la multicast non \`e realizzata da un sottosistema distinto da quello di calcolo, ma \`e mappata nei worker, si sono considerati i tempi di servizio della multicast relativi alle situazioni in cui il sistema non \`e collo di bottiglia. Le misurazioni sono mostrate in figura~\ref{fig:multicast}. I valori effettivi delle comunicazioni, in una applicazione \emph{reale}, risultano maggiori rispetto a quelli misurati con l'applicazione ping-pong. Si osserva inoltre un aumento del tempo di servizio con l'aumentare di $n$, soprattutto con dimensioni piccole dei dati. Anche in questo caso, tale tempo di servizio sarebbe dovuto essere costante. Per il supporto che usa la memoria condivisa possono essere portate le stesse argomentazioni della fase di calcolo.
\end{description}

\input{Benchmark_RowTime}
\input{Benchmark_MulticastTime}

\FloatBarrier

\subsubsection*{Confronto tra le due implementazioni}
Concludiamo infine con il vero scopo del benchmark, ovvero il confronto tra le due implementazioni. La figura~\ref{fig:compare} offre il confronto delle due implementazioni nella scalabilit\`a e nel tempo di servizio, con il sistema che \`e collo di bottiglia. Come atteso, le differenze tra le due versioni si osservano sulla grana pi\`u fine del calcolo nei worker, quindi sulla dimensione pi\`u piccola della matrice. All'aumentare della dimensione della matrice cresce la grana di calcolo e le differenze si assottigliano. 

Al fine di confrontare puntualmente le due realizzazioni del benchmark \`e utile la tabella~\ref{tab:scalability_serviceTime_bottleneck} proposta precedentemente. Considerando la dimensione delle matrici 56x56: l'implementazione su UDN ha un fattore di scalabilit\`a di 15 con 56 processi, contro una scalabilit\`a di 10 con 28 processi, della versione SM; il tempo di servizio effettivo della UDN \`e 5340.6 $\tau$ = 6.177 $\microsec$ con 56 processi, contro i 7552.140 $\tau$ = 8.735 $\microsec$ sempre con 28 processi, della SM. \\

Il benchmark e le misure fatte offrono spunti di riflessione sulle due versioni del supporto alle comunicazioni realizzati: 
\begin{description}
\item [tempo di calcolo] La misura sul tempo di calcolo di un singolo prodotto scalare ci permette di confrontare l'aumento che sia ha dei tale tempo con l'incremento dei $n$ nelle due implementazioni: graficamente ci\`o \`e osservabile confrontando le figure~\ref{fig:rowTime_int_udn}, \ref{fig:rowTime_int_sm}. L'implementazione su SM ha un tempo calcolo superiore a quello della versione su UDN, ci\`o \`e visibile soprattutto con la dimensione pi\`u piccola dei dati. Questo \`e significativo, in quanto l'uso di un supporto diverso e indipendente dalla memoria condivisa porta effettivamente ad una minore congestione del sottosistema della memoria e quindi a una minore degradazione del tempo di calcolo. Si osserva che il guadagno ottenuto non \`e elevato, ovvero, esiste anche in UDN una degradazione preponderante, tuttavia la differenza rispetto all'implementazione SM \`e visibile con tale grana del calcolo. Occorre considerare che la versione UDN del supporto fa uso della rete di interconnessione solo per la trasmissione dei puntatori, mentre la trasmissione vera e propria dei dati \`e affidata al sottosistema di cache e di memoria condivisa. Ci\`o fa ben sperare che una implementazione che sfrutti la UDN anche per la comunicazione tipi di dato arbitrari abbia influenza ancor pi\`u positiva nelle prestazioni globali rispetto alla comunicazione di riferimenti. In questo caso caso infatti anche la trasmissione delle strutture dati ``passerebbe'' per la UDN, riducendo cos\`i il grado di utilizzo della gerarchia di memoria condivisa.

Ci\`o fa sperare che una implementazione delle comunicazioni che sfrutti la UDN anche per la trasmissione dei dati abbia impatto molto maggiore nelle prestazioni complessive.
%2.273475 2.646978
\item [tempo della multicast] La lettura dei grafici del tempo di multicast (figura~\ref{fig:multicast}) quando il sistema non \`e collo di bottiglia, ci conferma che la latenza di comunicazione del supporto UDN si mantiene ben inferiore a quella della versione SM anche in una applicazione reale, e non solo nell'applicazione ping-pong. 
\end{description}
\input{Benchmark_Confronti}
