\section{Introduzione}
\label{sct:intro_intro}

Nella programmazione parallela \`e consolidato l'uso di paradigmi di parallelismo \cite{mattson2004patterns} al fine di ottenere una bassa complessit\`a di progettazione dell'applicazione, una semantica e un modello dei costi ben definiti. Il supporto a tali paradigmi \`e fornito mediante  un linguaggio parallelo di alto livello, oppure per mezzo di una libreria, e fa uso di meccanismi di cooperazione e comunicazione tra processi, astraendone dall'implementazione.
Allo stesso tempo, nell'ambito di applicazioni parallele con grana fine, \`e necessario disporre di meccanismi di cooperazione e comunicazione tra processi che siano il pi\`u possibile efficienti al fine di produrre prestazioni che scalino con il numero di processi coinvolti. Una implementazione di tali meccanismi che sia capace di minimizzare gli overhead \`e ottenibile se la progettazione \`e specifica rispetto alla macchina usata, sfruttando caratteristiche e strumenti della specifica macchina. 
Relativamente a macchine multi-core (CMP), generalmente con memoria condivisa, l'approccio classico allo sviluppo del supporto ai meccanismi fa uso dei livelli della memoria condivisa. Tuttavia alcune macchine CMP offrono al programmatore altri supporti architetturali che possono essere utilizzati in alternativa o in congiunzione alla memoria condivisa per il supporto ai meccanismi detti. 
Ad esempio \`e tendenza comune la realizzazione di nuove macchine CMP, soprattutto rivolte al networking o al processamento di segnali, caratterizzate da pi\`u reti on-chip di interconnessione dei core (NoC) usate per distinte finalit\`a. Alcune di queste macchine, come il Tilera \tile, o il NetLogic XLP832, permettono l'uso riservato all'utente di una di queste reti, al fine di realizzare comunicazioni inter-processors senza l'ausilio di memoria condivisa, e quindi senza ricorrere a spin-locks o semafori.

Da una parte la ricerca su sistemi di sintesi di paradigmi di parallelismo \`e in continua evoluzione e ha prodotto numerosi risultati \cite{cole2004bringing,gonzalez2010survey}, dall'altra parte \`e necessario cercare nuovi approcci all'implementazione di meccanismi di cooperazione e comunicazione tra processi. Si cercano quindi soluzioni avanzate che sfruttino le caratteristiche della specifica macchina per la realizzazione efficiente dei meccanismi fondamentali per un supporto ai paradigmi paralleli e che consentano la scalabilit\`a delle prestazioni in presenza di computazioni a grana fine.
Tali meccanismi saranno usati nel supporto alle forme di parallelismo e i dettagli implementativi risulteranno del tutto invisibili all'utente.  \\

In questo lavoro di tirocinio si indaga il possibile guadagno prestazionale nell'uso di reti di interconnessione tra core, rispetto ad un uso canonico della memoria condivisa, all'interno di un supporto a forme di comunicazione tra processi con modello a scambio di messaggi.
Si tratta di un primo esperimento su questa tematica, ragion per cui, il supporto non \`e generale ma \`e specializzato in un ben preciso tipo di comunicazione: l'uso di canali di comunicazione per lo scambio di riferimenti, con un grado di asincronia unitario.
\`E preso in esame il Network Processor Tilera \tile\ \cite{tileracorporation}, il quale integra, in un singolo chip, 64 core interconnessi da cinque reti di tipo mesh bidimensionale, caratterizzate da bassissima latenza di trasmissione. Queste strutture di interconnessione sono indipendenti e riservate a compiti specifici, una di queste, chiamata UDN, \`e a disposizione esclusiva dell'utente, che la pu\`o usare per realizzare comunicazioni tra core. 

Altri lavori hanno indagato le prestazioni derivanti dall'uso di questo tipo di supporto architetturale per l'implementazione di altri meccanismi che rivestono un ruolo chiave nel supporto alle applicazioni di grana fine. Ad esempio \`e pensabile l'utilizzo della UDN per ottimizzare l'implementazione di meccanismi di sincronizzazione tra processi, realizzando l'attesa di un evento come una ricezione sulla rete e rendendo il meccanismo di sveglia indipendente dalla memoria condivisa \cite{evalFineGrainSynchMech}.

Il principale vantaggio nell'utilizzo di strutture di interconnessione tra core per l'implementazione di un supporto alle comunicazioni risiede nella riduzione degli overhead presenti nelle implementazioni classiche (con memoria condivisa) dei canali di comunicazione tra processi, in particolare la latenza per la sincronizzazione a strutture dati condivise e la latenza per garantire la coerenza della cache. 
Esistono altri vantaggi nell'uso di supporti architetturali diversi dalla memoria condivisa per la realizzazione delle comunicazioni: 
\begin{itemize}
  \item Il disaccoppiamento tra la comunicazione dei processi e l'accesso ai dati in memoria riduce le richieste al sottosistema di memoria condivisa, ai livelli di cache e alle strutture di interconnessione che le gestiscono. Ci\`o produce una diminuzione del tempo di accesso medio alla memoria rispetto ad una realizzazione delle comunicazioni con la memoria.
  \item \`E possibile una forma parziale di sovrapposizione del tempo di comunicazione al tempo di calcolo, anche nel caso in cui i core della macchina non siano provvisti di processori di comunicazione. L'uso di una rete di interconnessione applica in modo primitivo il paradigma di comunicazione a scambio di messaggi, lasciando il processo mittente libero di eseguire altri compiti dopo aver istruito la rete all'invio del messaggio.
\end{itemize}

%% 1106 Il lavoro di questo tirocinio \`e una prima esperienza in questo ambito, e per questo motivo 
L'obiettivo del tirocinio \`e la realizzazione e il confronto di almeno due versioni dello stesso supporto alle comunicazioni: uno che utilizzi l'approccio ``classico'', e quindi sia implementato grazie all'uso della memoria condivisa; l'altro che usi l'approccio ``nuovo'', che consiste nell'uso della rete di interconnessione tra processori messa a disposizione dalla macchina Tilera \tile.
Le forme di comunicazione rese disponibili dal supporto sono quelle di uso pi\`u comune nei paradigmi di programmazione parallela: canale simmetrico unidirezionale e canale asimmetrico unidirezionale in ingresso. Entrambi trasportano oggetti di tipo ``riferimento'' e tutt'e due hanno grado di asincronia unitario. 
Oggetti di tipo riferimento hanno dimensione costante, uguale alla dimensione della parola della macchina; il fatto di non dover gestire messaggi di dimensione arbitraria facilita l'implementazione del supporto con UDN. 
Questo tipo di implementazione dei canali \`e frequente in chip multicore per applicazioni di computer networking, dove i messaggi scambiati tra i core sono riferimenti a strutture dati complesse che rappresentano, con un certo livello di indirezione, pacchetti allocati in memoria. D'altronde \`e necessario tenere presente che con questo approccio il trasferimento vero e proprio dei dati \`e comunque affidato al sottosistema di cache dell'architettura.

Il supporto alle comunicazioni \`e stato realizzato per far fronte a computazioni di grana molto fine, per questo scopo, scambiare riferimenti ai dati risulta adeguato. La progettazione del supporto \`e stata guidata dalla conoscenza di una metodologia di programmazione parallela che fa affidamento sulle forme di parallelismo al fine di dominare la complessit\`a di progettazione delle applicazioni parallele. Ci\`o ha derivato alcune scelte progettuali, ad esempio: il grado di asincronia unitario dei canali di comunicazione \`e accettabile per la maggior parte di forme parallele; un numero massimo di quattro canali \`e sufficiente per la realizzazione di molte forme parallele.

\subsection*{Struttura della relazione}
\begin{description}
\item [Capitolo 2]
Viene descritta l'architettura complessiva del Tilera \tile, la macchina multicore usata, con particolare attenzione alle caratteristiche e peculiarit\`a dei sottosistemi usati dal supporto: la gerarchia di memoria cache e la rete di interconnessione dei core;
\item [Capitolo 3]
Sono specificate le forme di comunicazione e i protocolli di comunicazione trattati. Viene inoltre fornita una descrizione ad alto livello delle implementazioni del supporto alle comunicazioni.
\item [Capitolo 4]
Nell'ultimo capitolo si descrivono gli esperimenti che sono stati realizzati al fine di confrontare le prestazioni delle due diverse implementazioni del supporto alle comunicazioni. 
\end{description}
